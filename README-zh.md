# å¼•è¨€
[Rain's SQLCoder](https://huggingface.co/SuanChang/rain-SQLCoder) æ˜¯è‡ªç„¶è¯­è¨€ç”Ÿæˆ SparkSQL çš„ SOTA å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰ï¼Œæ‹¥æœ‰ 32B å‚æ•°ï¼ŒåŸºäº [Qwen2.5-Coder-32B-Instruct](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct) å¾®è°ƒã€‚ Rain's SQLCoder é’ˆå¯¹è‡ªç„¶è¯­è¨€åˆ° SparkSQL è½¬æ¢ä»»åŠ¡è¿›è¡Œäº†ä¼˜åŒ–ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†æœ€é•¿è¾¾ 32k ä¸ª token çš„ä¸Šä¸‹æ–‡ï¼Œå°¤å…¶é€‚ç”¨äºå¤æ‚ä¸”å¤§è§„æ¨¡çš„ SQL æŸ¥è¯¢ç”Ÿæˆä»»åŠ¡ã€‚

<p align="center">
          ğŸ¤— <a href="https://huggingface.co/SuanChang/rain-SQLCoder">Hugging Face</a> | ğŸ–¥ï¸ <a href="https://www.suan-chang.com/">æ¼”ç¤º</a> | ğŸ’¬ <a href="./figures/wechat.png">å¾®ä¿¡</a> 
</p>

[English](./README.md) | [ä¸­æ–‡](./README-zh.md)

# æç¤ºè¯
Rain's SQLCoder é‡‡ç”¨äº† [Alpaca](https://github.com/tatsu-lab/stanford_alpaca) æ¨¡æ¿ï¼Œä½¿ç”¨çš„æç¤ºè¯å¦‚ä¸‹ã€‚
````
Below is an instruction that describes a task. 
Write a response that appropriately completes the request.

### Instruction:
[BEGIN OF TASK INSTRUCTION]
You are an expert in composing Spark SQL queries. You are given a user query and a set of table schemas.
Based on the user query, you need to generate one Spark SQL query to achieve the purpose.
{task description for date hint and related question and sqls}
[END OF TASK INSTRUCTION]

[BEGIN OF TABLE SCHEMAS]
{schemas}
[END OF TABLE SCHEMAS]

[BEGIN OF GENERATION HINT]
{date hint}
[END OF GENERATION HINT]

[BEGIN OF RELATED QUERIES]
{related question and sqls}
[END OF RELATED QUERIES]

[BEGIN OF FORMAT INSTRUCTION]
The output MUST strictly adhere to the following format, and NO other text MUST be included.
```sql
your output Spark SQL query
``` 
[END OF FORMAT INSTRUCTION]

[BEGIN OF QUERY]
User Query: {user question}
[END OF QUERY]

### Response:
````

# è¯„ä¼°
æˆ‘ä»¬æ²¿ç”¨äº† [SQL-Eval](https://github.com/defog-ai/sql-eval) ä¸­è¯„ä¼°é¢„æµ‹ç»“æœä¸æ ‡å‡†ç»“æœçš„é€»è¾‘ï¼š
1. å¦‚æœé¢„æµ‹çš„æ•°æ®å—å’Œæ ‡å‡†æ•°æ®å—å®Œå…¨ä¸€è‡´ï¼Œåˆ™é¢„æµ‹ç»“æœæ­£ç¡®ï¼›
2. æ ‡å‡†SQLä¸­ä¸åŒ…å«æ’åºé€»è¾‘ï¼Œä¸”é¢„æµ‹æ•°æ®å—å’Œæ ‡å‡†æ•°æ®å—åœ¨æ’åºä¹‹åå®Œå…¨ä¸€è‡´ï¼Œåˆ™é¢„æµ‹ç»“æœæ­£ç¡®ï¼›
3. å¦‚æœæ ‡å‡†æ•°æ®å—çš„åˆ—æ˜¯é¢„æµ‹æ•°æ®å—çš„å­é›†ï¼Œåˆ™é¢„æµ‹ç»“æœæ­£ç¡®ï¼›
4. å…¶ä½™æƒ…å†µå‡è®¤ä¸ºé¢„æµ‹ç»“æœé”™è¯¯ã€‚

# å®éªŒç»“æœ
æˆ‘ä»¬åœ¨ä¸¤ä¸ªæµ‹è¯•é›†ä¸Šå¯¹æ¯”äº†Rain's SQLCoderä¸å›½å†…å¤–å…ˆè¿›è‡ªç„¶è¯­è¨€å¤§æ¨¡å‹çš„ç”Ÿæˆå‡†ç¡®ç‡ã€‚å…¶ä¸­ï¼ŒåŸºå‡†æµ‹è¯•é›†ï¼ˆBenchmark Datasetï¼‰åŒ…å«åŸºç¡€æ ·æœ¬ï¼Œè€Œå¢å¼ºæµ‹è¯•é›†ï¼ˆEnhanced Datasetï¼‰åˆ™æ˜¯åœ¨åŸºå‡†æµ‹è¯•é›†çš„åŸºç¡€ä¸Šï¼Œé€šè¿‡åˆ†å±‚æŠ½æ ·æ–¹æ³•é€‰å–20%çš„æ ·æœ¬ï¼Œå¹¶è¡¥å……äº†ç›¸å…³çš„ç”¨æˆ·æŸ¥è¯¢åŠå¯¹åº”çš„SparkSQLè¯­å¥ï¼Œä»¥è¯„ä¼°æ¨¡å‹åœ¨å¢å¼ºä¸Šä¸‹æ–‡ä¿¡æ¯ä¸‹çš„æ€§èƒ½è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRain's SQLCoderåœ¨æŸ¥è¯¢æ„å›¾ç†è§£ã€SQLè¯­æ³•å‡†ç¡®æ€§å’Œå¤æ‚æŸ¥è¯¢å¤„ç†ç­‰æ–¹é¢å‡å±•ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ã€‚

## åŸºå‡†æµ‹è¯•é›†
<img src="./figures/benchmark_dataset_result.png" alt="benchmark" width=800>

## å¢å¼ºæµ‹è¯•é›†
<img src="./figures/enhanced_dataset_result.png" alt="enhanced" width=800>

# å¿«é€Ÿå¼€å§‹
æˆ‘ä»¬åœ¨æ­¤å¤„æä¾›ç¤ºä¾‹ï¼Œå¸®åŠ©æ‚¨å¿«é€ŸæŒæ¡å¦‚ä½•åŠ è½½å¹¶ä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹ã€‚
>æ³¨æ„: Rain's SQLCoder åªè¢«è®­ç»ƒç”¨äºç”Ÿæˆ `SELECT` è¯­å¥ï¼Œå½“è¡¨ç»“æ„æ— æ³•æ”¯æŒå›ç­”ç”¨æˆ·é—®é¢˜æ—¶ï¼Œæ¨¡å‹ä¼šæ‹’ç»å›ç­”ã€‚

````python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
from utils.prompt import SQLGeneratePrompt

model_name = "SuanChang/rain-SQLCoder"

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16,
    device_map="auto",
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

question = "What is the name of the department that offers a course that has a description including the word 'Statistics'?"
schemas = [
'''CREATE TABLE `course` (
    `crs_code` STRING,
    `dept_code` STRING,
    `crs_description` STRING,
    `crs_credit` DOUBLE
);''',
'''CREATE TABLE `department` (
    `dept_code` STRING,
    `dept_name` STRING,
    `school_code` STRING,
    `emp_num` INT,
    `dept_address` STRING,
    `dept_extension` INT
);''',
'''CREATE TABLE `student` (
    `stu_num` INT,
    `stu_lname` STRING,
    `stu_fname` STRING,
    `stu_init` STRING,
    `stu_dob` STRING,
    `stu_hrs` INT,
    `stu_class` STRING,
    `stu_gpa` DOUBLE,
    `stu_transfer` INT,
    `dept_code` STRING,
    `stu_phone` INT,
    `prof_num` INT
);'''
]
hint = "- Today is 2025-02-01."
data = dict(
    question=question,
    schema="\n\n".join(schemas),
    hint=hint,
    related_question_sqls=None,
)
text, _, _ = SQLGeneratePrompt.prompt(data)

model_inputs = tokenizer([text], return_tensors="pt").to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=32768
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]
response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]

print(response)

'''
```sql
SELECT d.dept_name FROM department d JOIN course c ON d.dept_code = c.dept_code WHERE c.crs_description LIKE '%Statistics%';
```
'''
````